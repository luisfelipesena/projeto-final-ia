# FALAS PARA APRESENTACAO - 15 MINUTOS
# Luis Felipe Sena
# MATA64 - Inteligencia Artificial - UFBA
# Dezembro 2025

================================================================================
SLIDE 1: TITULO (30 segundos)
================================================================================

Bom dia/boa tarde a todos. Meu nome e Luis Felipe e vou apresentar o projeto
final da disciplina de Inteligencia Artificial: um robo autonomo para coleta
de cubos coloridos.

O projeto integra tres tecnicas fundamentais de IA: redes neurais convolucionais
para classificacao de cores, logica fuzzy para navegacao reativa, e o algoritmo
A* para planejamento de trajetorias.

================================================================================
SLIDE 2: AGENDA (30 segundos)
================================================================================

A apresentacao esta dividida em cinco partes:

Primeiro, vou definir o problema e os desafios enfrentados.
Em seguida, apresento o sistema de percepcao - LIDAR, camera e rede neural.
Depois, explico como a logica fuzzy controla a navegacao.
Na quarta parte, mostro o planejamento de caminhos com A*.
Por fim, apresento a arquitetura do sistema e uma demonstracao.

================================================================================
SLIDE 3: O PROBLEMA (1 minuto)
================================================================================

O objetivo e coletar 15 cubos coloridos - vermelhos, verdes e azuis - e
depositar cada um na caixa de cor correspondente.

Usamos o KUKA YouBot, um robo com rodas Mecanum que permite movimento
omnidirecional - ou seja, ele pode se mover para frente, para os lados e
rotacionar simultaneamente.

A arena tem 7 metros por 4 metros, com 7 obstaculos fixos de madeira
posicionados estrategicamente. Os cubos estao espalhados aleatoriamente
pela arena no inicio da simulacao.

Como podem ver no diagrama, as caixas de deposito estao nas extremidades:
verde em cima, azul embaixo, e vermelho a direita.

================================================================================
SLIDE 4: RESTRICOES DO PROJETO (1 minuto)
================================================================================

O projeto tem requisitos obrigatorios e proibicoes importantes.

Obrigatoriamente, precisamos usar uma rede neural - seja MLP ou CNN - para
alguma tarefa de classificacao. Tambem precisamos usar logica fuzzy para
controle. E os sensores disponiveis sao LIDAR e camera RGB.

Por outro lado, e proibido usar GPS. O robo deve estimar sua posicao usando
apenas odometria - integrando as velocidades das rodas ao longo do tempo.
Tambem e proibida teleoperacao - o robo deve ser completamente autonomo.
E nao podemos acessar diretamente a posicao dos cubos no simulador.

O grande desafio e navegar de forma autonoma em um ambiente onde os cubos
podem ser empurrados acidentalmente, mudando a configuracao do ambiente.

================================================================================
SLIDE 5: SENSORES DO YOUBOT (1 minuto)
================================================================================

O YouBot possui tres tipos de sensores principais.

O LIDAR tem campo de visao de 180 graus, com 180 feixes de laser. O alcance
vai de 10 centimetros ate 5 metros. Temos 4 LIDARs cobrindo 360 graus.
Usamos o LIDAR para detectar obstaculos e construir uma grade de ocupacao.

A camera RGB tem resolucao de 128 por 128 pixels. Usamos tanto a Recognition
API do Webots para detectar objetos quanto a nossa CNN para classificar cores.

Para deteccao de colisao em curta distancia, temos 8 sensores infravermelhos:
6 frontais/traseiros e 2 laterais. Os sensores laterais sao essenciais porque
o LIDAR frontal nao cobre os lados do robo.

================================================================================
SLIDE 6: RECOGNITION API DO WEBOTS (1 minuto)
================================================================================

Antes de falar da CNN, preciso explicar a Recognition API do Webots.

A Recognition API e um sistema do simulador que retorna informacoes sobre
objetos visiveis pela camera. Ela fornece um objeto WbCameraRecognitionObject
com: posicao 3D relativa a camera, tamanho do bounding box, e cores definidas
no campo recognitionColors dos objetos no simulador.

Importante: a Recognition API usa informacao do grafo de cena do Webots -
ou seja, e ground truth do simulador. Por isso, embora usemos ela para
detectar a posicao dos cubos, precisamos de uma rede neural propria para
classificar a cor - esse e um requisito obrigatorio do projeto.

A Recognition API nos da "onde esta o cubo", e a CNN nos da "qual cor e".

================================================================================
SLIDE 7: REDE NEURAL - MOBILENETV3 (1 minuto 30 segundos)
================================================================================

Para classificacao de cores, usamos uma CNN baseada na MobileNetV3-Small.

A MobileNetV3 e uma arquitetura otimizada para dispositivos moveis, desenvolvida
pelo Google em 2019. Ela usa convolucoes depthwise e pointwise separadas, que
reduzem drasticamente o numero de parametros e operacoes.

Tecnicamente:
- Convolucao depthwise: um filtro por canal de entrada
- Convolucao pointwise: 1x1 para combinar canais
- Isso reduz computacao de O(k2 vezes Ci vezes Co) para O(k2 vezes Ci + Ci vezes Co)

Usamos transfer learning em duas fases:
1. Backbone congelado, treinar so classificador (256 para 3 neuronios)
2. Fine-tuning completo com learning rate reduzido

Resultado: 99.4% de acuracia. Quando a confianca e baixa, usamos fallback HSV.

================================================================================
SLIDE 8: LOGICA FUZZY - CONCEITO (1 minuto)
================================================================================

A logica fuzzy e fundamental para o controle de navegacao. Mas por que fuzzy?

Permite controle suave e continuo, sem transicoes bruscas. Lida bem com
incerteza dos sensores. E as regras sao expressas em linguagem natural.

No grafico, vemos as funcoes de pertinencia para distancia ao obstaculo:
- "muito perto": maximo de 0 a 25 centimetros
- "perto": maximo em 45 centimetros
- "longe": comeca a subir apos 40 centimetros

Estas funcoes transformam valores crisp em graus de pertinencia.

================================================================================
SLIDE 9: REGRAS FUZZY DE NAVEGACAO (1 minuto)
================================================================================

As regras fuzzy sao divididas em dois grupos: desvio e alinhamento.

As regras de desvio tratam da seguranca:
- SE obstaculo muito perto, ENTAO reverso mais strafe lateral
- SE obstaculo perto, ENTAO reduzir velocidade
- SE lateral bloqueado, ENTAO strafe na direcao oposta

As regras de alinhamento tratam do direcionamento ao objetivo:
- SE angulo grande, ENTAO apenas rotacionar, sem avancar
- SE angulo medio, ENTAO avancar lento enquanto rotaciona
- SE angulo pequeno, ENTAO avancar rapido

O processo completo tem quatro etapas. Primeiro, os valores dos sensores
passam pela fuzzificacao, calculando os graus de pertinencia. Depois, as
regras sao avaliadas. Entao, a defuzzificacao calcula os comandos de
velocidade. Usamos o metodo do centroide ponderado para obter valores
continuos de velocidade linear, lateral e angular.

================================================================================
SLIDE 10: ALGORITMO A* - VISAO GERAL (1 minuto)
================================================================================

Para planejamento global, usamos A* de Hart, Nilsson e Raphael de 1968.

A funcao de custo e f(n) = g(n) + h(n), onde g e o custo ate aqui e h e a
heuristica ate o objetivo. Usamos distancia de Manhattan como heuristica.

A grade de ocupacao tem celulas de 12 por 12 centimetros, totalizando
58 por 33 celulas para a arena. O LIDAR atualiza continuamente a grade
usando raycasting com algoritmo de Bresenham.

No diagrama: S = inicio, G = objetivo. A linha azul mostra o caminho
encontrado pelo A*, contornando obstaculos pelo caminho de menor custo.

================================================================================
SLIDE 11: INFLACAO DE OBSTACULOS (45 segundos)
================================================================================

O robo nao e um ponto - o YouBot tem 58 por 38 centimetros. Por isso inflamos
os obstaculos por 30 centimetros, que e aproximadamente metade da diagonal
do robo mais uma margem de seguranca.

No diagrama: marrom e o obstaculo real, e a area pontilhada vermelha e a
zona inflada. O A* planeja evitando a zona maior, garantindo que o robo
inteiro passa com seguranca.

================================================================================
SLIDE 12: ARQUITETURA MODULAR (45 segundos)
================================================================================

O codigo foi dividido em modulos para melhor manutencao:

- constants.py: configuracao da arena e posicoes das caixas
- routes.py: planejamento de rotas estrategicas para ir e voltar
- occupancy_grid.py: grade de ocupacao e algoritmo A*
- fuzzy_navigator.py: regras fuzzy para navegacao reativa
- youbot_controller.py: maquina de estados principal
- color_classifier.py: rede neural MobileNetV3

Essa separacao de responsabilidades facilita testes e manutencao.

================================================================================
SLIDE 13: MAQUINA DE ESTADOS (45 segundos)
================================================================================

Maquina de estados finita com 6 estados:
- SEARCH: explorar arena procurando cubos
- APPROACH: alinhar e aproximar do cubo detectado
- GRASP: descer braco, fechar garra, verificar agarrou
- TO_BOX: navegar ate caixa de cor correspondente via A*
- DROP: soltar cubo sobre a caixa
- RETURN: voltar ao spawn para buscar proximo cubo

O ciclo repete 15 vezes, uma para cada cubo.

================================================================================
SLIDE 14: PIPELINE COMPLETO (45 segundos)
================================================================================

Este diagrama mostra como os componentes se integram:

Sensores -> Processamento -> Decisao -> Acao

- LIDAR alimenta a grade de ocupacao
- Camera alimenta Recognition API e CNN
- Sensores de distancia alimentam o controlador Fuzzy
- Grade vai para A*, CNN vai para FSM
- FSM decide comandos para motores

================================================================================
SLIDE 15: SEQUENCIA DE COLETA (45 segundos)
================================================================================

Visualizacao do ciclo completo de coleta em 6 passos:

1. SEARCH: robo varre arena com LIDAR, camera detecta cubo
2. APPROACH: alinha com cubo, fuzzy controla aproximacao
3. GRASP: braco desce, garra fecha, verifica agarrou
4. TO_BOX: A* planeja rota ate caixa de cor correspondente
5. DROP: solta cubo, verifica gripper vazio e distancia
6. RETURN: volta ao spawn com waypoints adaptativos

================================================================================
SLIDE 16: NAVEGACAO A* EM ACAO (30 segundos)
================================================================================

Este diagrama mostra o A* planejando rota na arena real.

Os quadrados marrons sao obstaculos com zona inflada em volta.
A linha azul mostra o caminho planejado. Os pontos azuis sao waypoints.
O robo segue esses waypoints enquanto fuzzy evita colisoes locais.

================================================================================
SLIDE 17: DEMONSTRACAO (2 minutos)
================================================================================

[INICIAR VIDEO/SIMULACAO]

Observem:
- Exploracao no modo SEARCH
- Deteccao e aproximacao do cubo
- Braco agarrando o cubo
- Navegacao A* ate a caixa desviando de obstaculos
- Deposito e RETORNO ao spawn para buscar proximo cubo

Prestem atencao no sistema de navegacao que evita colisoes usando a
combinacao de A* global com fuzzy local.

[ENCERRAR VIDEO/SIMULACAO]

================================================================================
SLIDE 18: LIMITACOES DOS ALGORITMOS (1 minuto)
================================================================================

Cada algoritmo tem limitacoes conhecidas na literatura:

A* de Hart e colaboradores, 1968:
- Caminhos podem passar muito perto de obstaculos
- Muitos nos redundantes, busca pode ser lenta
Mitigacao: inflacao de obstaculos por 30 centimetros

Fuzzy de Zadeh, 1965:
- Pode gerar oscilacoes em navegacao
- Susceptivel a minimos locais
Mitigacao: navegacao car-like com velocidade lateral limitada e timeout de waypoint

CNN MobileNetV3 de Howard, 2019:
- Sensivel a variacoes de iluminacao
- Trade-off entre precisao e latencia
Mitigacao: fallback HSV quando confianca menor que 0.5

================================================================================
SLIDE 19: CONCLUSAO (30 segundos)
================================================================================

Integracao bem-sucedida de tres tecnicas de IA:
- CNN: 99.4% acuracia para classificacao de cor
- Fuzzy: navegacao reativa suave
- A*: planejamento global de trajetorias

O sistema e robusto, com recuperacao automatica de travamentos.
A arquitetura modular facilita manutencao e extensao.

================================================================================
SLIDE 20: REFERENCIAS E PERGUNTAS (30 segundos)
================================================================================

Referencias principais:
- Hart, Nilsson, Raphael 1968 - Algoritmo A*
- Zadeh 1965 - Conjuntos Fuzzy
- Howard et al. 2019 - MobileNetV3

Obrigado pela atencao. Estou a disposicao para perguntas.

================================================================================
FIM - TEMPO TOTAL ESTIMADO: ~15 MINUTOS (20 SLIDES)
================================================================================

DICAS PARA APRESENTACAO:
- Manter ritmo fluido, ~45s por slide em media
- Usar os diagramas TikZ nos slides para apoio visual
- Enfatizar as mitigacoes para cada limitacao dos algoritmos
- Referenciar autores: Hart/Nilsson/Raphael (A*), Zadeh (Fuzzy), Howard (MobileNetV3)
- Explicar que Recognition API e ground truth, CNN e requisito obrigatorio
- Ressaltar arquitetura modular como boa pratica de engenharia
- Conectar teoria com exemplos praticos da simulacao
- Demonstracao ao vivo e o ponto alto - ter simulacao pronta!
