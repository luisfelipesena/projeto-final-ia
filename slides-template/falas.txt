================================================================================
FALAS PARA APRESENTAÇÃO - YouBot Autônomo
MATA64 - Inteligência Artificial | UFBA
Tempo Total: ~15 minutos
================================================================================

================================================================================
SLIDE 1: TÍTULO (30 segundos)
================================================================================

"Boa tarde a todos. Meu nome é Luis Felipe e vou apresentar meu projeto final
de Inteligência Artificial: um sistema autônomo para o robô YouBot realizar
coleta e organização de cubos coloridos."

================================================================================
SLIDE 2: AGENDA (30 segundos)
================================================================================

"Dividi a apresentação em cinco partes: primeiro vou explicar o objetivo e os
desafios do projeto, depois a arquitetura geral do sistema, em seguida as
redes neurais que desenvolvi, o controlador fuzzy, e por fim uma demonstração
do robô funcionando na simulação."

================================================================================
SLIDE 3: O PROBLEMA (1 minuto)
================================================================================

"O desafio é fazer o robô coletar 15 cubos coloridos - verdes, azuis e
vermelhos - e depositar cada um na caixa da cor correspondente. O robô precisa
navegar por uma arena com obstáculos fixos, que são caixotes de madeira.

A principal restrição é que NÃO podemos usar GPS na demonstração final. Toda
a navegação deve ser baseada apenas nos sensores: LIDAR para detectar obstáculos
e câmera para identificar os cubos e suas cores.

Os cubos aparecem em posições aleatórias a cada execução, então o sistema
precisa ser robusto para encontrá-los em qualquer lugar da arena."

================================================================================
SLIDE 4: SENSORES (1 minuto)
================================================================================

"O YouBot possui dois sensores principais que utilizei. O LIDAR Hokuyo faz
uma varredura de 270 graus e retorna 667 pontos de distância, com alcance de
até 5 metros. Usei ele para detectar obstáculos e criar um mapa local.

A câmera RGB tem resolução 512 por 512 pixels e um campo de visão de
aproximadamente 60 graus. Com ela faço a detecção dos cubos e a classificação
de cores.

Essa combinação de sensores permite navegação segura e identificação precisa
dos alvos sem depender de GPS."

================================================================================
SLIDE 5: PIPELINE (1 minuto 30 segundos)
================================================================================

"Este diagrama mostra o fluxo completo do sistema. Do lado esquerdo temos os
sensores alimentando o sistema de percepção. O LIDAR passa por uma CNN de uma
dimensão que gera um mapa de obstáculos em 9 setores ao redor do robô.
A imagem da câmera vai para outra CNN que classifica as cores dos cubos detectados.

No centro está o controlador fuzzy, que recebe as informações de percepção e
gera os comandos de velocidade: linear e angular. Junto com ele temos a máquina
de estados que coordena as ações do braço e garra.

Do lado direito estão os atuadores: a base móvel omnidirecional e o braço com
garra para pegar os cubos. Todo esse ciclo executa a mais de 10 hertz, garantindo
reatividade em tempo real."

================================================================================
SLIDE 6: MÁQUINA DE ESTADOS (1 minuto)
================================================================================

"A máquina de estados tem 6 estados principais. O robô começa em BUSCAR,
explorando a arena. Quando detecta um cubo, transita para APROXIMAR. Ao chegar
perto o suficiente, vai para PEGAR e executa a sequência de grasp.

Com o cubo na garra, passa para NAVEGAR até a caixa da cor correspondente.
Ao chegar, entra em DEPOSITAR para soltar o cubo. Depois volta para BUSCAR
e repete até coletar todos os 15 cubos.

O estado DESVIAR é especial - ele tem prioridade máxima e é ativado sempre
que um obstáculo fica muito próximo, menos de 30 centímetros. Isso garante
que o robô nunca colida, mesmo durante outras operações."

================================================================================
SLIDE 7: RNA LIDAR (1 minuto 30 segundos)
================================================================================

"Para processar o LIDAR, desenvolvi uma arquitetura híbrida. Um branch de CNN
unidimensional recebe os 667 pontos normalizados e extrai 64 features através
de três camadas convolucionais.

Em paralelo, calculamos 6 features estatísticas: mínimo, máximo, média, desvio
padrão, e gradientes. Essas features complementam o que a CNN aprende.

Na fusão, concatenamos as 70 features e passamos por um MLP classificador
que gera probabilidades de ocupação para cada um dos 9 setores. Isso permite
ao controlador saber exatamente de qual direção vem o perigo.

Essa arquitetura foi inspirada no PointNet de Qi e colaboradores, adaptada
para nosso caso específico com apenas cerca de 50 mil parâmetros."

================================================================================
SLIDE 8: RNA CÂMERA (1 minuto)
================================================================================

"Para classificação de cores, usei uma CNN leve com três blocos convolucionais.
Cada bloco tem convolução, batch normalization, ReLU e max pooling. Depois um
global average pooling reduz para um vetor de 128 dimensões, que passa por
duas camadas fully connected até o softmax de 3 classes.

Com cerca de 250 mil parâmetros, conseguimos rodar a mais de 10 FPS mesmo em
CPU, sem precisar de GPU.

Como fallback robusto, implementei também segmentação HSV tradicional. Isso
garante funcionamento mesmo se o modelo neural falhar, usando ranges de cores
calibrados para o ambiente de simulação."

================================================================================
SLIDE 9: SEGMENTAÇÃO HSV (45 segundos)
================================================================================

"A segmentação HSV usa faixas de valores calibradas para cada cor. Verde fica
entre 35 e 85 no canal H, azul entre 100 e 130, e vermelho precisa de duas
faixas porque ele 'dá a volta' no espectro: 0 a 10 e 160 a 180.

O pipeline converte de RGB para HSV, aplica threshold por cor, faz operações
morfológicas para limpar ruído, e encontra contornos para gerar bounding boxes.

Essa abordagem é muito robusta às variações de iluminação do simulador."

================================================================================
SLIDE 10: CONTROLADOR FUZZY (1 minuto 30 segundos)
================================================================================

"O controlador fuzzy é baseado na teoria de conjuntos fuzzy de Zadeh de 1965
e no modelo de Mamdani e Assilian de 1975.

Temos 6 variáveis de entrada: distância e ângulo para o obstáculo mais próximo,
distância e ângulo para o cubo detectado, e dois booleanos indicando se há
cubo visível e se está segurando um cubo.

As saídas são a velocidade linear, entre -0.3 e +0.3 metros por segundo, a
velocidade angular, entre -0.5 e +0.5 radianos por segundo, e a ação atual
do robô.

No total são 25 regras organizadas em três grupos: 15 regras de segurança
para evitar obstáculos, 5 regras de busca para explorar o ambiente, e 5 regras
de aproximação para se alinhar com os cubos detectados."

================================================================================
SLIDE 11: FUNÇÕES DE PERTINÊNCIA (45 segundos)
================================================================================

"As funções de pertinência são todas triangulares para simplicidade e eficiência.
Para distância ao obstáculo temos 5 termos: muito perto, perto, médio, longe e
muito longe. Para ângulos temos 7 termos, de negativo grande até positivo grande.

As saídas de velocidade também usam funções triangulares: parar, devagar, médio
e rápido para velocidade linear, e girar esquerda, centro e girar direita para
velocidade angular.

A defuzzificação usa o método do centróide, que é o mais comum e produz saídas
suaves."

================================================================================
SLIDE 12: EXEMPLOS DE REGRAS (1 minuto)
================================================================================

"Vou mostrar algumas regras exemplo. A R001 é a regra de parada de emergência:
SE a distância ao obstáculo É muito perto E o ângulo É zero, ou seja, bem
na frente, ENTÃO a velocidade linear É parar E a velocidade angular É girar
para direita.

A R002 trata de obstáculo perto mas num ângulo positivo, à direita: nesse caso
desaceleramos e giramos para a esquerda para desviar.

Já as regras de aproximação funcionam diferente. A R016 diz: SE tem cubo
detectado E a distância É longe E o ângulo É zero, ENTÃO vai rápido em
linha reta. A R017 ajusta se o cubo está um pouco para o lado."

================================================================================
SLIDE 13: INFERÊNCIA (45 segundos)
================================================================================

"O processo de inferência segue o fluxo padrão: as entradas crisp são
fuzzificadas, passam pelas 25 regras do tipo Mamdani, e a saída fuzzy é
defuzzificada pelo centróide para gerar os comandos crisp de velocidade.

Usei a biblioteca scikit-fuzzy do Python, que é bem otimizada. Conseguimos
performance de aproximadamente 30 milissegundos por inferência, o que permite
rodar a mais de 30 hertz - bem acima da meta de 10 hertz."

================================================================================
SLIDE 14: MÉTRICAS (45 segundos)
================================================================================

"Esta tabela resume as métricas de performance do sistema. A meta era coletar
todos os 15 cubos, com precisão de cor acima de 95%, zero colisões, tempo
total menor que 5 minutos, e frequência de controle acima de 10 hertz.

O sistema roda no Webots R2023b com Python 3.11, PyTorch e scikit-fuzzy.
Testamos em CPU Intel i7 sem usar GPU."

[Nota: preencher os valores obtidos na demonstração]

================================================================================
SLIDE 15: DEMONSTRAÇÃO (2-3 minutos)
================================================================================

"Agora vou mostrar o robô funcionando. Vocês podem observar como ele:
- Explora a arena procurando cubos
- Detecta um cubo e se aproxima
- Identifica a cor corretamente
- Pega com a garra
- Navega até a caixa certa
- Deposita e volta a buscar

Prestem atenção também no desvio de obstáculos - o robô nunca colide mesmo
passando perto dos caixotes."

[Rodar demonstração ou vídeo]

================================================================================
SLIDE 16: LIÇÕES APRENDIDAS (45 segundos)
================================================================================

"Os principais desafios foram: primeiro, navegar sem GPS usando apenas odometria
e mapa local, que acumula erro com o tempo. Segundo, integrar as redes neurais
com o controlador fuzzy em tempo real, respeitando o limite de 100ms por ciclo.
Terceiro, calibrar os parâmetros fuzzy para ter comportamento suave mas reativo.

Para trabalhos futuros, podemos implementar SLAM para mapeamento global mais
preciso, planejamento de trajetória com A* para otimizar rotas, e até
treinamento end-to-end com aprendizado por reforço."

================================================================================
SLIDE 17: REFERÊNCIAS (30 segundos)
================================================================================

"As principais referências foram o livro Deep Learning de Goodfellow para as
redes neurais, os papers originais de Zadeh e Mamdani para lógica fuzzy,
PointNet de Qi para processamento de nuvens de pontos, e Probabilistic Robotics
de Thrun para navegação robótica."

================================================================================
SLIDE 18: ENCERRAMENTO (30 segundos)
================================================================================

"Com isso concluo a apresentação. Agradeço a atenção e estou à disposição
para perguntas. Obrigado!"

================================================================================
NOTAS IMPORTANTES
================================================================================

1. NÃO MOSTRAR CÓDIGO-FONTE (desconto de 3-10 pontos)
2. Usar figuras, gráficos e vídeos - pouco texto
3. Citar as referências verbalmente quando relevante
4. Demonstração deve mostrar TODO o ciclo de coleta
5. Confirmar que GPS está desabilitado antes de gravar
6. Tempo máximo: 15 minutos

================================================================================
PERGUNTAS ESPERADAS E RESPOSTAS
================================================================================

P: Por que não usou SLAM?
R: SLAM seria mais preciso mas mais complexo. Para esta arena limitada,
   odometria com mapa local foi suficiente e mais simples de implementar.

P: Como garantiu que não há colisões?
R: O estado DESVIAR tem prioridade máxima e é ativado automaticamente quando
   um obstáculo fica a menos de 30cm. As regras fuzzy também começam a
   desacelerar e girar bem antes desse limite.

P: Por que 25 regras fuzzy?
R: Seguimos o requisito mínimo de 20 regras do projeto. As 5 extras
   melhoraram o comportamento em situações de borda.

P: O sistema funciona em hardware real?
R: O código foi desenvolvido para simulação mas a arquitetura é portável.
   Precisaria apenas ajustar calibração de sensores e velocidades.

================================================================================
