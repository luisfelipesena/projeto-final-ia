# Plano de Execu√ß√£o - YouBot Aut√¥nomo

**Projeto:** Sistema Aut√¥nomo de Coleta e Organiza√ß√£o de Objetos
**Aluno:** Luis Felipe Cordeiro Sena
**Data Limite:** 06/01/2026, 23:59
**Status:** Planejamento Conclu√≠do

---

## üéØ Objetivo Final

Desenvolver sistema aut√¥nomo para YouBot que:
- Coleta 15 cubos coloridos (verde, azul, vermelho) distribu√≠dos aleatoriamente
- Identifica cor via c√¢mera RGB
- Deposita em caixa correspondente
- Evita obst√°culos usando LIDAR
- **SEM GPS** - navega√ß√£o baseada apenas em sensores

**Requisitos T√©cnicos Obrigat√≥rios:**
1. ‚úÖ RNA (MLP ou CNN) para LIDAR/mapeamento
2. ‚úÖ L√≥gica Fuzzy para controle de a√ß√µes

---

## üìã Fases do Projeto

### Fase 0: Setup e Documenta√ß√£o ‚úÖ
**Prazo:** Completado
**Status:** ‚úÖ CONCLU√çDO

- [x] Estrutura de projeto criada
- [x] CLAUDE.md com contexto do projeto
- [x] REFERENCIAS.md com base cient√≠fica
- [x] TODO.md (este arquivo) para planejamento
- [x] DECISIONS.md para rastreamento de decis√µes
- [x] .gitignore configurado

---

### Fase 1: Ambiente e Explora√ß√£o Inicial
**Prazo:** 3 dias
**Objetivo:** Familiariza√ß√£o com Webots e sensores do YouBot

#### 1.1 Setup do Webots ‚úÖ CONCLU√çDO
- [x] Instalar/atualizar Webots (manual) - R2023b instalado
- [x] Verificar vers√£o do Python (compatibilidade com Webots) - Python 3.14.0 com venv
- [x] Testar abertura do mundo IA_20252.wbt - Carrega em ~5s, funcional
- [x] Verificar spawn de cubos pelo supervisor - 15/15 cubos spawnados com sucesso
- [x] Documentar setup em DECISIONS.md (DECIS√ÉO 005-010 adicionadas)
- [x] Criar documenta√ß√£o de setup (specs/001-webots-setup/* completo)
- [x] Criar testes de valida√ß√£o automatizados (tests/test_webots_setup.py - 6/8 passed)

**Deliverable:** ‚úÖ Simula√ß√£o rodando sem erros | DECIS√ÉO 010: World file R2025a funciona em R2023b com warnings n√£o-cr√≠ticos

#### 1.2 Explora√ß√£o dos Controles Base ‚úÖ CONCLU√çDO
- [x] Testar movimentos da base (forward, backward, strafe, rotate)
- [x] Testar comandos do bra√ßo (set_height, set_orientation)
- [x] Testar garra (grip, release)
- [x] Documentar limites de movimento
- [x] Criar script de teste b√°sico: `tests/test_basic_controls.py`

**Deliverable:** ‚úÖ Script de teste validando todos os controles (13/13 testes implementados)

#### 1.3 An√°lise dos Sensores ‚úÖ CONCLU√çDO
- [x] **LIDAR:**
  - [x] Ler dados brutos (range_image)
  - [x] Entender formato (n√∫mero de pontos, range, FOV)
  - [x] Visualizar varredura (matplotlib/plot)
  - [x] Identificar obst√°culos na visualiza√ß√£o
- [x] **C√¢mera RGB:**
  - [x] Capturar frames
  - [x] Verificar resolu√ß√£o e FPS
  - [x] Testar detec√ß√£o de cores (threshold simples)
  - [x] Salvar imagens de exemplo
- [x] Criar notebook: `notebooks/01_sensor_exploration.ipynb`

**Deliverable:** ‚úÖ Notebook com visualiza√ß√µes e an√°lises dos sensores

#### 1.4 Mapeamento da Arena ‚úÖ CONCLU√çDO
- [x] Medir dimens√µes da arena manualmente
- [x] Identificar posi√ß√µes aproximadas das caixas de dep√≥sito
- [x] Mapear distribui√ß√£o t√≠pica de obst√°culos
- [x] Documentar coordenadas em `docs/arena_map.md`

**Deliverable:** ‚úÖ Mapa esquem√°tico da arena (7.0√ó4.0m documentado)

**Refer√™ncias Fase 1:**
- Bischoff et al. (2011): YouBot specifications
- Michel (2004): Webots documentation

---

### Fase 2: Percep√ß√£o com Redes Neurais
**Prazo:** 10 dias
**Status:** üü° INFRAESTRUTURA COMPLETA - Falta treinamento e integra√ß√£o final
**Objetivo:** Implementar detec√ß√£o de obst√°culos (LIDAR) e classifica√ß√£o de cores (RGB)

**üì¶ COMPLETADO (PR #3):**
- [x] Infraestrutura de dados (coleta, anota√ß√£o, augmentation, splits)
- [x] Arquiteturas de redes neurais implementadas
- [x] Data loaders PyTorch com augmentation
- [x] Scripts de valida√ß√£o e testes
- [x] Documenta√ß√£o completa (DECIS√ÉO 016-017)

**üì¶ COMPLETADO (PR #4 - specs/002-script-updates):**
- [x] Scripts de coleta atualizados com suporte a mock e metadata externa
- [x] Scripts de anota√ß√£o com auto-labeling (LIDAR threshold, Camera HSV)
- [x] Script de gera√ß√£o de manifests (`generate_dataset_manifest.py`)
- [x] Script de split atualizado para usar manifests (`split_dataset.py`)
- [x] Todos os scripts verificados com dados mock

**‚ö†Ô∏è PENDENTE (Retornar ap√≥s Fase 3):**

#### 2.1 Processamento LIDAR com RNA

**2.1.1 Abordagem Implementada: Hybrid MLP + 1D-CNN** ‚úÖ
- [x] Arquitetura Hybrid: `src/perception/models/lidar_net.py`
  - [x] CNN branch: Conv1D(1‚Üí32‚Üí64‚Üí64) + GlobalAvgPool
  - [x] Hand-crafted features: min, mean, std, occupancy, symmetry, variance
  - [x] MLP classifier: Fusion(70‚Üí128‚Üí64‚Üí9) + Sigmoid
  - [x] ~250K par√¢metros
- [x] LIDARProcessor: `src/perception/lidar_processor.py`
- [x] ObstacleMap: Estrutura 9-sector
- [x] Data augmentation: noise, dropout, rotation

**‚ö†Ô∏è FALTA EXECUTAR:**
- [ ] **T018:** Coletar 1000+ scans LIDAR no Webots
  ```bash
  python scripts/collect_lidar_data.py
  ```
- [ ] **T019:** Revisar/corrigir labels se necess√°rio
  ```bash
  python scripts/annotate_lidar.py
  ```
- [ ] **T024-T025:** Criar notebook de treinamento LIDAR
  - [ ] `notebooks/lidar_training.ipynb`
  - [ ] Adam optimizer, BCE loss, 100-200 epochs
  - [ ] Early stopping (patience=20)
- [ ] **T026:** Treinar modelo e validar: >90% accuracy, <100ms latency
- [ ] **T027-T028:** Exportar modelo treinado
  - [ ] Salvar como TorchScript: `models/lidar_net.pt`
  - [ ] Salvar metadata: `models/lidar_net_metadata.json`

#### 2.1.3 Detec√ß√£o de Obst√°culos
- [x] LIDARProcessor com inference implementado
- [x] ObstacleMap com m√©todos de consulta
- [ ] **T029-T033:** Integrar no controller Webots (ap√≥s treinamento)

**Deliverable:** ‚è≥ M√≥dulo LIDAR funcionando com >90% precis√£o

#### 2.2 Detec√ß√£o de Cubos com CNN

**2.2.1 Arquitetura Implementada: Lightweight CNN** ‚úÖ
- [x] **DECIS√ÉO 017:** Custom Lightweight CNN escolhida
- [x] Arquitetura: `src/perception/models/camera_net.py`
  - [x] Conv2D(3‚Üí32‚Üí64‚Üí128) + BatchNorm + ReLU + MaxPool
  - [x] GlobalAvgPool + FC(128‚Üí64‚Üí3) + Dropout(0.5)
  - [x] ~250K par√¢metros
- [x] Fallback: ResNet18 transfer learning (se accuracy <93%)
- [x] CameraDataset com augmentation
- [x] Data augmentation: brightness, hue, flip, rotation

**‚ö†Ô∏è FALTA EXECUTAR:**
- [ ] **T034:** Coletar 500+ imagens no Webots
  ```bash
  python scripts/collect_camera_data.py
  ```
- [ ] **T035:** Revisar/corrigir labels e bboxes
  ```bash
  python scripts/annotate_camera.py
  ```
- [ ] **T038-T039:** Criar notebook de treinamento Camera
  - [ ] `notebooks/camera_training.ipynb`
  - [ ] SGD+momentum, CrossEntropy loss, 30-50 epochs
  - [ ] StepLR scheduler, class weighting
- [ ] **T040:** Treinar e validar: >95% per-color, >10 FPS
- [ ] **T041:** Se accuracy <93%, usar ResNet18 fallback
- [ ] **T042-T043:** Exportar modelo treinado
  - [ ] Salvar como TorchScript: `models/camera_net.pt`
  - [ ] Salvar metadata: `models/camera_net_metadata.json`

**2.2.3 Detec√ß√£o e Localiza√ß√£o de Cubos**
- [ ] **T044-T048:** Implementar CubeDetector completo
  - [ ] HSV color segmentation para region proposals
  - [ ] Bbox + color classification
  - [ ] Distance estimation (focal_length=462, cube_size=0.05m)
  - [ ] Angle estimation (bearing)
  - [ ] Non-Max Suppression (IoU=0.5)
- [ ] **T049-T051:** Integrar no controller Webots (ap√≥s treinamento)

**Deliverable:** ‚è≥ Detector de cubos com >95% precis√£o em cores

#### 2.3 Integra√ß√£o Percep√ß√£o
- [ ] **T052-T067:** Implementar PerceptionSystem completo (Fase 5)
  - [ ] Classe que unifica LIDAR + Camera
  - [ ] Output estruturado: obstacles + cubes
  - [ ] WorldState tracking
  - [ ] Sensor fusion e filtros
- [ ] Implementar em: `src/perception/perception_system.py`
- [ ] Testes de integra√ß√£o: `tests/test_perception_integration.py`

**Deliverable:** ‚è≥ Sistema de percep√ß√£o integrado e testado

**üìù NOTA:** Infraestrutura completa permite desenvolvimento paralelo de Fase 3 (Controle Fuzzy).
Retornar aqui ap√≥s Fase 3 para executar coleta de dados e treinamento.

**Refer√™ncias Fase 2:**
- Goodfellow et al. (2016): Deep Learning fundamentals
- Qi et al. (2017): PointNet architecture
- Redmon et al. (2016): YOLO detection
- Liu et al. (2016): SSD for small objects

---

### Fase 3: Controle com L√≥gica Fuzzy
**Prazo:** 7 dias
**Objetivo:** Implementar controlador fuzzy para navega√ß√£o e a√ß√µes

#### 3.1 Design do Controlador Fuzzy

**3.1.1 Definir Vari√°veis Lingu√≠sticas**

**Inputs:**
- [ ] `distance_to_obstacle`: {muito_perto, perto, medio, longe}
- [ ] `angle_to_obstacle`: {esquerda, centro, direita}
- [ ] `distance_to_cube`: {muito_perto, perto, medio, longe}
- [ ] `angle_to_cube`: {esquerda_forte, esquerda, centro, direita, direita_forte}
- [ ] `cube_detected`: {sim, nao} (crisp)
- [ ] `holding_cube`: {sim, nao} (crisp)

**Outputs:**
- [ ] `linear_velocity`: {parar, devagar, medio, rapido}
- [ ] `angular_velocity`: {esquerda_forte, esquerda, reto, direita, direita_forte}
- [ ] `action`: {buscar, aproximar, pegar, levar_caixa, soltar}

**Fun√ß√µes de Pertin√™ncia:**
- [ ] Definir fun√ß√µes (triangular, trapezoidal, gaussiana)
- [ ] Plotar e validar visualmente
- [ ] Documentar ranges em `docs/fuzzy_membership.md`

#### 3.1.2 Definir Regras Fuzzy**

Categorias de regras:
- [ ] **Evita√ß√£o de obst√°culos** (prioridade m√°xima):
  ```
  SE distance_to_obstacle √â muito_perto ENT√ÉO linear_velocity √â parar E angular_velocity √â esquerda_forte
  SE distance_to_obstacle √â perto E angle_to_obstacle √â centro ENT√ÉO linear_velocity √â devagar E angular_velocity √â direita
  ```
- [ ] **Busca de cubos**:
  ```
  SE cube_detected √â nao E obstacle_free ENT√ÉO action √â buscar E linear_velocity √â medio E angular_velocity √â esquerda
  ```
- [ ] **Aproxima√ß√£o de cubos**:
  ```
  SE cube_detected √â sim E distance_to_cube √â longe ENT√ÉO action √â aproximar E linear_velocity √â medio
  SE distance_to_cube √â perto ENT√ÉO linear_velocity √â devagar
  SE distance_to_cube √â muito_perto ENT√ÉO action √â pegar
  ```
- [ ] **Navega√ß√£o para caixa**:
  ```
  SE holding_cube √â sim ENT√ÉO action √â levar_caixa
  ```
- [ ] Criar arquivo: `src/control/fuzzy_rules.txt` com todas as regras

**Total de regras:** ~20-30 regras bem definidas

#### 3.1.3 Implementa√ß√£o
- [ ] Usar biblioteca `scikit-fuzzy`
- [ ] Implementar controlador Mamdani
- [ ] M√©todos de defuzzifica√ß√£o: centroid
- [ ] Classe `FuzzyController` em: `src/control/fuzzy_controller.py`
- [ ] Testes unit√°rios: `tests/test_fuzzy.py`

#### 3.2 M√°quina de Estados
- [ ] Definir estados do rob√¥:
  - [ ] `SEARCHING`: Procurando cubos
  - [ ] `APPROACHING`: Aproximando de cubo detectado
  - [ ] `GRASPING`: Pegando cubo
  - [ ] `NAVIGATING_TO_BOX`: Indo para caixa correspondente
  - [ ] `DEPOSITING`: Depositando cubo
  - [ ] `AVOIDING`: Evitando obst√°culo (override)
- [ ] Transi√ß√µes entre estados
- [ ] Implementar em: `src/control/state_machine.py`

#### 3.3 Integra√ß√£o Controle
- [ ] Conectar fuzzy controller com state machine
- [ ] Input: dados de percep√ß√£o
- [ ] Output: comandos para base, arm, gripper
- [ ] Implementar em: `src/control/robot_controller.py`

**Deliverable:** Controlador fuzzy funcional com m√°quina de estados

**Refer√™ncias Fase 3:**
- Zadeh (1965): Fuzzy Sets theory
- Mamdani & Assilian (1975): Fuzzy controller
- Saffiotti (1997): Fuzzy navigation
- Antonelli et al. (2007): Path tracking

---

### Fase 4: Navega√ß√£o e Path Planning
**Prazo:** 5 dias
**Objetivo:** Implementar estrat√©gias de navega√ß√£o eficientes

#### 4.1 Mapeamento Local
- [ ] Criar occupancy grid simplificado
  - [ ] Baseado em leituras LIDAR recentes
  - [ ] Atualiza√ß√£o incremental
  - [ ] Resolu√ß√£o: 10cm x 10cm
- [ ] Marcar c√©lulas: livre, ocupado, desconhecido
- [ ] Implementar em: `src/navigation/local_map.py`

#### 4.2 Planejamento de Trajet√≥ria
- [ ] **Abordagem Simples (Recomendada):**
  - [ ] Navega√ß√£o reativa pura (fuzzy)
  - [ ] Sem path planning expl√≠cito
  - [ ] Evita√ß√£o local de obst√°culos
- [ ] **Abordagem Avan√ßada (Opcional):**
  - [ ] A* ou RRT para path planning
  - [ ] Planejar trajeto para cubo/caixa
  - [ ] Implementar em: `src/navigation/path_planner.py`

**Escolha:** Documentar em DECISIONS.md

#### 4.3 Localiza√ß√£o Relativa
- [ ] Odometria baseada em comandos de velocidade
- [ ] Estimativa de posi√ß√£o relativa (sem GPS!)
- [ ] Reset ao depositar cubo
- [ ] Implementar em: `src/navigation/odometry.py`

**Deliverable:** Sistema de navega√ß√£o funcional

**Refer√™ncias Fase 4:**
- Thrun et al. (2005): Probabilistic Robotics
- Siegwart et al. (2011): Mobile Robots

---

### Fase 5: Manipula√ß√£o e Grasping
**Prazo:** 4 dias
**Objetivo:** Sequ√™ncias confi√°veis de pegar e soltar cubos

#### 5.1 Sequ√™ncia de Grasping
- [ ] Definir posi√ß√µes do bra√ßo para pegar cubo:
  - [ ] Reset ‚Üí posi√ß√£o preparat√≥ria
  - [ ] Preparat√≥ria ‚Üí posi√ß√£o de pegada (FRONT_FLOOR)
  - [ ] Abrir garra
  - [ ] Descer bra√ßo at√© cubo
  - [ ] Fechar garra
  - [ ] Levantar bra√ßo
- [ ] Timing entre comandos (espera estabiliza√ß√£o)
- [ ] Verifica√ß√£o de sucesso (sensor de for√ßa ou timeout)
- [ ] Implementar em: `src/manipulation/grasping.py`

#### 5.2 Sequ√™ncia de Deposi√ß√£o
- [ ] Posicionar rob√¥ perto da caixa
- [ ] Mover bra√ßo para posi√ß√£o sobre caixa
- [ ] Abrir garra
- [ ] Retrair bra√ßo
- [ ] Reset para posi√ß√£o inicial
- [ ] Implementar em: `src/manipulation/depositing.py`

#### 5.3 Identifica√ß√£o das Caixas
- [ ] Mapear posi√ß√µes fixas das caixas (verde, azul, vermelha)
- [ ] Navega√ß√£o para caixa baseada na cor do cubo segurado
- [ ] Hardcode inicial de posi√ß√µes (simplifica√ß√£o)
- [ ] Opcional: Detec√ß√£o visual das caixas

**Deliverable:** Sequ√™ncias de manipula√ß√£o confi√°veis (>80% sucesso)

**Refer√™ncias Fase 5:**
- Craig (2005): Robot kinematics
- Bohg et al. (2014): Grasp synthesis

---

### Fase 6: Integra√ß√£o do Sistema Completo
**Prazo:** 5 dias
**Objetivo:** Loop principal funcionando end-to-end

#### 6.1 Arquitetura do Main Controller
- [ ] Implementar loop principal em: `src/main_controller.py`
```python
while cubos_coletados < 15:
    # 1. Percep√ß√£o
    obstacles, cubes = perception_system.update()

    # 2. Decis√£o (State Machine + Fuzzy)
    state, action = controller.decide(obstacles, cubes, robot_state)

    # 3. Atua√ß√£o
    if state == SEARCHING:
        base.move(vx, vy, omega)
    elif state == GRASPING:
        grasping.execute()
    elif state == DEPOSITING:
        depositing.execute()

    # 4. Update estado
    robot_state.update()

    step()
```

#### 6.2 Fluxo Completo
- [ ] Estado inicial: Busca
- [ ] Detec√ß√£o de cubo ‚Üí Aproxima√ß√£o
- [ ] Chegou perto ‚Üí Pegar
- [ ] Pegou ‚Üí Navegar para caixa
- [ ] Chegou na caixa ‚Üí Depositar
- [ ] Depositou ‚Üí Voltar para busca
- [ ] Repetir at√© 15 cubos

#### 6.3 Tratamento de Erros
- [ ] Timeout em estados (se travar)
- [ ] Retentar grasp se falhar
- [ ] Evitar ficar preso em cantos
- [ ] Log de eventos: `logs/execution.log`

#### 6.4 Testes de Integra√ß√£o
- [ ] Teste com 3 cubos primeiro
- [ ] Depois 5, 10, 15
- [ ] Diferentes configura√ß√µes de obst√°culos
- [ ] Medir taxa de sucesso

**Deliverable:** Sistema completo funcional

---

### Fase 7: Otimiza√ß√£o e Refinamento
**Prazo:** 5 dias
**Objetivo:** Melhorar performance e confiabilidade

#### 7.1 Ajuste de Par√¢metros
- [ ] Fuzzy:
  - [ ] Fun√ß√µes de pertin√™ncia
  - [ ] Pesos das regras
  - [ ] Thresholds de decis√£o
- [ ] Percep√ß√£o:
  - [ ] Thresholds de confian√ßa
  - [ ] Filtros de ru√≠do
- [ ] Navega√ß√£o:
  - [ ] Velocidades m√°ximas
  - [ ] Dist√¢ncias seguras
- [ ] Manipula√ß√£o:
  - [ ] Timings
  - [ ] Posi√ß√µes do bra√ßo

#### 7.2 M√©tricas de Performance
- [ ] Taxa de sucesso na coleta (%)
- [ ] Tempo m√©dio por cubo (s)
- [ ] N√∫mero de colis√µes
- [ ] Precis√£o na deposi√ß√£o por cor (%)
- [ ] Documentar em: `docs/performance_metrics.md`

#### 7.3 Debugging
- [ ] Adicionar logs detalhados
- [ ] Visualiza√ß√µes em tempo real:
  - [ ] Mapa LIDAR
  - [ ] Cubos detectados
  - [ ] Estado atual
- [ ] Modo de replay para an√°lise

**Deliverable:** Sistema otimizado com m√©tricas documentadas

---

### Fase 8: Documenta√ß√£o e Apresenta√ß√£o
**Prazo:** 7 dias
**Objetivo:** Material para v√≠deo de 15 minutos

#### 8.1 Documenta√ß√£o T√©cnica
- [ ] `README.md` com:
  - [ ] Descri√ß√£o do projeto
  - [ ] Como executar
  - [ ] Estrutura de c√≥digo
  - [ ] Depend√™ncias
- [ ] `docs/architecture.md`:
  - [ ] Diagramas de arquitetura
  - [ ] Fluxo de dados
  - [ ] Decis√µes de design
- [ ] `docs/results.md`:
  - [ ] M√©tricas finais
  - [ ] An√°lise de resultados

#### 8.2 Material Visual (SEM C√ìDIGO!)

**REGRA DE OURO:** Slides = IMAGENS E FIGURAS. Texto excessivo perde pontos!

- [ ] Adaptar template LaTeX: `slides-template/main.tex`
  - [ ] Atualizar t√≠tulo: "YouBot Aut√¥nomo - Sistema de Coleta com RNA + Fuzzy"
  - [ ] Autor: Luis Felipe Cordeiro Sena
  - [ ] Estrutura: 7 se√ß√µes (Intro, Teoria, Arquitetura, Percep√ß√£o, Controle, Demo, Resultados)
  - [ ] Integrar bibliografia (Top 10 de REFERENCIAS.md)
  - [ ] **M√°ximo 3-4 bullet points por slide, NUNCA par√°grafos**
- [ ] Roteiro de fala: `slides-template/falas.txt`
  - [ ] Ajustar para apresenta√ß√£o individual de 15 min
  - [ ] Sincronizar com estrutura de slides
  - [ ] Foco: Voc√™ explica verbalmente, slides s√≥ apoiam visualmente
- [ ] Diagramas:
  - [ ] Arquitetura do sistema
  - [ ] Pipeline de percep√ß√£o
  - [ ] Fun√ß√µes de pertin√™ncia fuzzy
  - [ ] Regras fuzzy (visual)
  - [ ] M√°quina de estados
  - [ ] Modelo cinem√°tico do YouBot
- [ ] Gr√°ficos:
  - [ ] Curvas de aprendizado (RNA)
  - [ ] M√©tricas de performance
  - [ ] Compara√ß√£o de abordagens
- [ ] V√≠deos/GIFs:
  - [ ] Rob√¥ coletando cubos (diferentes √¢ngulos)
  - [ ] Evita√ß√£o de obst√°culos
  - [ ] Sequ√™ncia de grasp
  - [ ] Visualiza√ß√£o LIDAR em tempo real
  - [ ] Detec√ß√£o de cubos com bounding boxes
- [ ] Ferramentas:
  - [ ] Draw.io para diagramas
  - [ ] Matplotlib/seaborn para gr√°ficos
  - [ ] OBS Studio para grava√ß√£o

#### 8.3 Roteiro do V√≠deo (15 min)
- [ ] **Intro (1 min):**
  - [ ] Apresenta√ß√£o do problema
  - [ ] Objetivos do projeto
- [ ] **Fundamenta√ß√£o Te√≥rica (3 min):**
  - [ ] Redes Neurais (LIDAR + C√¢mera)
  - [ ] L√≥gica Fuzzy (Controle)
  - [ ] Cita√ß√µes: Top 10 refer√™ncias
- [ ] **Arquitetura do Sistema (2 min):**
  - [ ] Diagrama completo
  - [ ] M√≥dulos e integra√ß√£o
- [ ] **Percep√ß√£o (2 min):**
  - [ ] Processamento LIDAR
  - [ ] Detec√ß√£o de cubos
  - [ ] Demonstra√ß√£o visual
- [ ] **Controle Fuzzy (2 min):**
  - [ ] Vari√°veis e regras
  - [ ] M√°quina de estados
  - [ ] Exemplos de decis√£o
- [ ] **Demonstra√ß√£o (4 min):**
  - [ ] V√≠deo do rob√¥ em a√ß√£o
  - [ ] Coleta completa de 15 cubos
  - [ ] Diferentes cen√°rios
- [ ] **Resultados (1 min):**
  - [ ] M√©tricas de performance
  - [ ] Taxa de sucesso
  - [ ] Gr√°ficos

#### 8.4 Grava√ß√£o e Edi√ß√£o
- [ ] Gravar √°udio (microfone de qualidade)
- [ ] Gravar tela com apresenta√ß√£o
- [ ] Gravar simula√ß√£o no Webots
- [ ] Editar no DaVinci Resolve / Premiere
- [ ] Adicionar legendas (opcional)
- [ ] M√∫sica de fundo discreta (opcional)
- [ ] Exportar em 1080p

#### 8.5 Submiss√£o
- [ ] Upload no Youtube (n√£o listado)
- [ ] C√≥digo em .zip
- [ ] Preencher formul√°rio de entrega
- [ ] Verificar prazo: **06/01/2026, 23:59**

**Deliverable:** V√≠deo de 15min + c√≥digo-fonte

**Refer√™ncias:** Todas as Top 10 de REFERENCIAS.md

---

## üèóÔ∏è Estrutura de C√≥digo Final

```
projeto-final-ia/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ perception/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lidar_processor.py       # RNA para LIDAR
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cube_detector.py         # CNN para cubos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ perception_system.py     # Integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ control/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fuzzy_controller.py      # L√≥gica Fuzzy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fuzzy_rules.txt          # Regras
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state_machine.py         # Estados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ robot_controller.py      # Integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ navigation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local_map.py             # Mapa local
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ odometry.py              # Odometria
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ path_planner.py          # Opcional
‚îÇ   ‚îú‚îÄ‚îÄ manipulation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grasping.py              # Sequ√™ncia grasp
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ depositing.py            # Sequ√™ncia deposi√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ main_controller.py           # Loop principal
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ lidar_model.pth              # Modelo LIDAR
‚îÇ   ‚îî‚îÄ‚îÄ cube_detector.pth            # Modelo CNN
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_basic_controls.py
‚îÇ   ‚îú‚îÄ‚îÄ test_perception.py
‚îÇ   ‚îú‚îÄ‚îÄ test_fuzzy.py
‚îÇ   ‚îî‚îÄ‚îÄ test_integration.py
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_sensor_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_lidar_training.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_cube_detection_training.ipynb
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ arena_map.md
‚îÇ   ‚îú‚îÄ‚îÄ fuzzy_membership.md
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md
‚îÇ   ‚îú‚îÄ‚îÄ performance_metrics.md
‚îÇ   ‚îî‚îÄ‚îÄ results.md
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ execution.log
‚îú‚îÄ‚îÄ media/
‚îÇ   ‚îú‚îÄ‚îÄ diagrams/
‚îÇ   ‚îú‚îÄ‚îÄ graphs/
‚îÇ   ‚îî‚îÄ‚îÄ videos/
‚îú‚îÄ‚îÄ IA_20252/                        # C√≥digo base (existente)
‚îú‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ REFERENCIAS.md
‚îú‚îÄ‚îÄ TODO.md                          # Este arquivo
‚îú‚îÄ‚îÄ DECISIONS.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ .gitignore
```

---

## üìä Cronograma Visual

```
Semanas 1-2:  [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] Fase 1-2: Setup + Percep√ß√£o (RNA)
Semanas 3:    [‚ñà‚ñà‚ñà‚ñà]     Fase 3: Controle Fuzzy
Semana 4:     [‚ñà‚ñà‚ñà]      Fase 4-5: Navega√ß√£o + Manipula√ß√£o
Semana 5:     [‚ñà‚ñà‚ñà‚ñà]     Fase 6: Integra√ß√£o
Semana 6:     [‚ñà‚ñà‚ñà]      Fase 7: Otimiza√ß√£o
Semanas 7-8:  [‚ñà‚ñà‚ñà‚ñà‚ñà]    Fase 8: Documenta√ß√£o + V√≠deo
                         [BUFFER: 1 semana antes da entrega]
```

**Total:** ~8 semanas + 1 buffer = 9 semanas at√© 06/01/2026

---

## ‚úÖ Crit√©rios de Sucesso

### M√≠nimo Vi√°vel (Aprova√ß√£o)
- [ ] Sistema coleta pelo menos 10/15 cubos
- [ ] Identifica√ß√£o de cores >80% precisa
- [ ] Evita√ß√£o de obst√°culos funcional
- [ ] RNA para LIDAR implementada e funcional
- [ ] L√≥gica Fuzzy implementada e funcional
- [ ] V√≠deo de 15min explicando tudo (SEM C√ìDIGO!)

### Excel√™ncia (Nota M√°xima)
- [ ] Sistema coleta 15/15 cubos consistentemente
- [ ] Identifica√ß√£o de cores >95% precisa
- [ ] Navega√ß√£o eficiente (tempo otimizado)
- [ ] Zero colis√µes com obst√°culos
- [ ] Apresenta√ß√£o visual impec√°vel
- [ ] Fundamenta√ß√£o te√≥rica s√≥lida
- [ ] C√≥digo bem documentado e organizado

---

## üîß Depend√™ncias T√©cnicas

### Python Packages
```txt
# requirements.txt
numpy>=1.24.0
scipy>=1.10.0
matplotlib>=3.7.0
scikit-learn>=1.3.0
scikit-fuzzy>=0.4.2
opencv-python>=4.8.0
torch>=2.0.0                # PyTorch para CNNs
torchvision>=0.15.0
pillow>=10.0.0
jupyter>=1.0.0
pytest>=7.4.0
```

### Instala√ß√£o
```bash
pip install -r requirements.txt
```

---

## üìù Notas Importantes

1. **Sem GPS:** Toda navega√ß√£o baseada em sensores (LIDAR + c√¢mera)
2. **Sem modificar supervisor.py:** Sob pena de perda de pontos
3. **Sem mostrar c√≥digo no v√≠deo:** Perda de 3-10 pontos
4. **Foco visual:** Figuras, gr√°ficos, v√≠deos > texto
5. **Prazo fatal:** 06/01/2026, 23:59
6. **Documentar tudo:** DECISIONS.md a cada escolha t√©cnica

---

## üéì Refer√™ncias por Fase

**Setup:** Michel (2004)
**Percep√ß√£o:** Goodfellow (2016), Qi (2017), Redmon (2016), Liu (2016)
**Controle:** Zadeh (1965), Mamdani (1975), Saffiotti (1997)
**Navega√ß√£o:** Thrun (2005), Siegwart (2011)
**Manipula√ß√£o:** Craig (2005), Bohg (2014)
**Integra√ß√£o:** Todas as Top 10

Ver REFERENCIAS.md para lista completa.

---

**√öltima atualiza√ß√£o:** 2025-11-18
**Pr√≥xima revis√£o:** Ap√≥s conclus√£o de cada fase
