# Plano de Execu√ß√£o - YouBot Aut√¥nomo

**Projeto:** Sistema Aut√¥nomo de Coleta e Organiza√ß√£o de Objetos
**Aluno:** Luis Felipe Cordeiro Sena
**Data Limite:** 06/01/2026, 23:59
**Status:** Planejamento Conclu√≠do

---

## üéØ Objetivo Final

Desenvolver sistema aut√¥nomo para YouBot que:
- Coleta 15 cubos coloridos (verde, azul, vermelho) distribu√≠dos aleatoriamente
- Identifica cor via c√¢mera RGB
- Deposita em caixa correspondente
- Evita obst√°culos usando LIDAR
- **SEM GPS** - navega√ß√£o baseada apenas em sensores

**Requisitos T√©cnicos Obrigat√≥rios:**
1. ‚úÖ RNA (MLP ou CNN) para LIDAR/mapeamento
2. ‚úÖ L√≥gica Fuzzy para controle de a√ß√µes

---

## üìã Fases do Projeto

### Fase 0: Setup e Documenta√ß√£o ‚úÖ
**Prazo:** Completado
**Status:** ‚úÖ CONCLU√çDO

- [x] Estrutura de projeto criada
- [x] CLAUDE.md com contexto do projeto
- [x] REFERENCIAS.md com base cient√≠fica
- [x] TODO.md (este arquivo) para planejamento
- [x] DECISIONS.md para rastreamento de decis√µes
- [x] .gitignore configurado

---

### Fase 1: Ambiente e Explora√ß√£o Inicial
**Prazo:** 3 dias
**Objetivo:** Familiariza√ß√£o com Webots e sensores do YouBot

#### 1.1 Setup do Webots
- [ ] Instalar/atualizar Webots (manual - seguir quickstart.md)
- [x] Verificar vers√£o do Python (compatibilidade com Webots) - Script criado em tests/
- [ ] Testar abertura do mundo IA_20252.wbt (manual - ap√≥s instala√ß√£o Webots)
- [ ] Verificar spawn de cubos pelo supervisor (manual - ap√≥s instala√ß√£o Webots)
- [x] Documentar setup em DECISIONS.md (DECIS√ÉO 005-008 adicionadas)
- [x] Criar documenta√ß√£o de setup (specs/001-webots-setup/* completo)
- [x] Criar testes de valida√ß√£o automatizados (tests/test_webots_setup.py)

**Deliverable:** Simula√ß√£o rodando sem erros

#### 1.2 Explora√ß√£o dos Controles Base
- [ ] Testar movimentos da base (forward, backward, strafe, rotate)
- [ ] Testar comandos do bra√ßo (set_height, set_orientation)
- [ ] Testar garra (grip, release)
- [ ] Documentar limites de movimento
- [ ] Criar script de teste b√°sico: `tests/test_basic_controls.py`

**Deliverable:** Script de teste validando todos os controles

#### 1.3 An√°lise dos Sensores
- [ ] **LIDAR:**
  - [ ] Ler dados brutos (range_image)
  - [ ] Entender formato (n√∫mero de pontos, range, FOV)
  - [ ] Visualizar varredura (matplotlib/plot)
  - [ ] Identificar obst√°culos na visualiza√ß√£o
- [ ] **C√¢mera RGB:**
  - [ ] Capturar frames
  - [ ] Verificar resolu√ß√£o e FPS
  - [ ] Testar detec√ß√£o de cores (threshold simples)
  - [ ] Salvar imagens de exemplo
- [ ] Criar notebook: `notebooks/01_sensor_exploration.ipynb`

**Deliverable:** Notebook com visualiza√ß√µes e an√°lises dos sensores

#### 1.4 Mapeamento da Arena
- [ ] Medir dimens√µes da arena manualmente
- [ ] Identificar posi√ß√µes aproximadas das caixas de dep√≥sito
- [ ] Mapear distribui√ß√£o t√≠pica de obst√°culos
- [ ] Documentar coordenadas em `docs/arena_map.md`

**Deliverable:** Mapa esquem√°tico da arena

**Refer√™ncias Fase 1:**
- Bischoff et al. (2011): YouBot specifications
- Michel (2004): Webots documentation

---

### Fase 2: Percep√ß√£o com Redes Neurais
**Prazo:** 10 dias
**Objetivo:** Implementar detec√ß√£o de obst√°culos (LIDAR) e classifica√ß√£o de cores (RGB)

#### 2.1 Processamento LIDAR com RNA

**2.1.1 Abordagem Simplificada (Recomendada)**
- [ ] Converter LIDAR 2D para representa√ß√£o process√°vel
  - [ ] Grid ocupancy map (2D array)
  - [ ] Polar representation (dist√¢ncia, √¢ngulo)
- [ ] Arquitetura MLP:
  - [ ] Input: LIDAR ranges (normalized)
  - [ ] Hidden layers: 2-3 camadas
  - [ ] Output: Classifica√ß√£o de setores (livre/ocupado)
- [ ] Treinar com dados sint√©ticos:
  - [ ] Gerar cen√°rios variados no Webots
  - [ ] Coletar 1000+ exemplos de varreduras LIDAR
  - [ ] Labels: obst√°culo detectado em cada setor
- [ ] Validar precis√£o (>90% em test set)
- [ ] Implementar em: `src/perception/lidar_processor.py`

**2.1.2 Abordagem Avan√ßada (Opcional - se tempo permitir)**
- [ ] Adaptar PointNet para LIDAR 2D
  - [ ] Converter ranges para point cloud
  - [ ] Simplificar arquitetura (menos layers)
- [ ] Usar modelo pr√©-treinado e fine-tuning
- [ ] Implementar em: `src/perception/lidar_pointnet.py`

**Escolha:** Documentar abordagem escolhida em DECISIONS.md

#### 2.1.3 Detec√ß√£o de Obst√°culos
- [ ] Processar output da RNA para identificar obst√°culos
- [ ] Calcular dist√¢ncia e √¢ngulo de cada obst√°culo
- [ ] Implementar filtro de ru√≠do (m√©dia m√≥vel)
- [ ] Criar visualiza√ß√£o em tempo real

**Deliverable:** M√≥dulo LIDAR funcionando com >90% precis√£o

**2.2 Detec√ß√£o de Cubos com CNN**

**2.2.1 Escolha de Arquitetura**
Op√ß√µes (escolher UMA e documentar em DECISIONS.md):
- [ ] **Op√ß√£o A:** YOLO pr√©-treinado + transfer learning
  - R√°pido, tempo real
  - Bom para detec√ß√£o + classifica√ß√£o simult√¢nea
- [ ] **Op√ß√£o B:** SSD (melhor para objetos pequenos)
- [ ] **Op√ß√£o C:** CNN customizada simples
  - Sliding window + classifica√ß√£o de cores
  - Menos overhead, mais controle

**2.2.2 Implementa√ß√£o**
- [ ] Preparar dataset:
  - [ ] Coletar 500+ imagens da c√¢mera no Webots
  - [ ] Anotar bounding boxes de cubos
  - [ ] Labels: cor (verde/azul/vermelho)
  - [ ] Split: 70% treino, 15% valida√ß√£o, 15% teste
- [ ] Treinar modelo:
  - [ ] Se YOLO: fine-tune √∫ltimas camadas
  - [ ] Se custom: treinar do zero com data augmentation
  - [ ] Early stopping com validation loss
  - [ ] Salvar melhor modelo em `models/cube_detector.pth`
- [ ] Validar:
  - [ ] Precis√£o por cor (>95%)
  - [ ] FPS (target: >10 fps)
  - [ ] Falsos positivos/negativos
- [ ] Implementar em: `src/perception/cube_detector.py`

**2.2.3 Classifica√ß√£o de Cores (Alternativa Simples)**
Se detec√ß√£o for muito complexa:
- [ ] Usar threshold RGB simples
- [ ] Definir ranges para verde, azul, vermelho
- [ ] Aplicar em regi√£o detectada
- [ ] Validar com imagens de teste

**Deliverable:** Detector de cubos com >95% precis√£o em cores

**2.3 Integra√ß√£o Percep√ß√£o**
- [ ] Classe `PerceptionSystem` que unifica:
  - [ ] LIDAR ‚Üí obst√°culos
  - [ ] C√¢mera ‚Üí cubos coloridos
- [ ] Output estruturado:
  ```python
  {
    'obstacles': [(dist, angle), ...],
    'cubes': [{'color': 'green', 'position': (x,y), 'distance': d}, ...]
  }
  ```
- [ ] Implementar em: `src/perception/perception_system.py`
- [ ] Testes unit√°rios: `tests/test_perception.py`

**Deliverable:** Sistema de percep√ß√£o integrado e testado

**Refer√™ncias Fase 2:**
- Goodfellow et al. (2016): Deep Learning fundamentals
- Qi et al. (2017): PointNet architecture
- Redmon et al. (2016): YOLO detection
- Liu et al. (2016): SSD for small objects

---

### Fase 3: Controle com L√≥gica Fuzzy
**Prazo:** 7 dias
**Objetivo:** Implementar controlador fuzzy para navega√ß√£o e a√ß√µes

#### 3.1 Design do Controlador Fuzzy

**3.1.1 Definir Vari√°veis Lingu√≠sticas**

**Inputs:**
- [ ] `distance_to_obstacle`: {muito_perto, perto, medio, longe}
- [ ] `angle_to_obstacle`: {esquerda, centro, direita}
- [ ] `distance_to_cube`: {muito_perto, perto, medio, longe}
- [ ] `angle_to_cube`: {esquerda_forte, esquerda, centro, direita, direita_forte}
- [ ] `cube_detected`: {sim, nao} (crisp)
- [ ] `holding_cube`: {sim, nao} (crisp)

**Outputs:**
- [ ] `linear_velocity`: {parar, devagar, medio, rapido}
- [ ] `angular_velocity`: {esquerda_forte, esquerda, reto, direita, direita_forte}
- [ ] `action`: {buscar, aproximar, pegar, levar_caixa, soltar}

**Fun√ß√µes de Pertin√™ncia:**
- [ ] Definir fun√ß√µes (triangular, trapezoidal, gaussiana)
- [ ] Plotar e validar visualmente
- [ ] Documentar ranges em `docs/fuzzy_membership.md`

#### 3.1.2 Definir Regras Fuzzy**

Categorias de regras:
- [ ] **Evita√ß√£o de obst√°culos** (prioridade m√°xima):
  ```
  SE distance_to_obstacle √â muito_perto ENT√ÉO linear_velocity √â parar E angular_velocity √â esquerda_forte
  SE distance_to_obstacle √â perto E angle_to_obstacle √â centro ENT√ÉO linear_velocity √â devagar E angular_velocity √â direita
  ```
- [ ] **Busca de cubos**:
  ```
  SE cube_detected √â nao E obstacle_free ENT√ÉO action √â buscar E linear_velocity √â medio E angular_velocity √â esquerda
  ```
- [ ] **Aproxima√ß√£o de cubos**:
  ```
  SE cube_detected √â sim E distance_to_cube √â longe ENT√ÉO action √â aproximar E linear_velocity √â medio
  SE distance_to_cube √â perto ENT√ÉO linear_velocity √â devagar
  SE distance_to_cube √â muito_perto ENT√ÉO action √â pegar
  ```
- [ ] **Navega√ß√£o para caixa**:
  ```
  SE holding_cube √â sim ENT√ÉO action √â levar_caixa
  ```
- [ ] Criar arquivo: `src/control/fuzzy_rules.txt` com todas as regras

**Total de regras:** ~20-30 regras bem definidas

#### 3.1.3 Implementa√ß√£o
- [ ] Usar biblioteca `scikit-fuzzy`
- [ ] Implementar controlador Mamdani
- [ ] M√©todos de defuzzifica√ß√£o: centroid
- [ ] Classe `FuzzyController` em: `src/control/fuzzy_controller.py`
- [ ] Testes unit√°rios: `tests/test_fuzzy.py`

#### 3.2 M√°quina de Estados
- [ ] Definir estados do rob√¥:
  - [ ] `SEARCHING`: Procurando cubos
  - [ ] `APPROACHING`: Aproximando de cubo detectado
  - [ ] `GRASPING`: Pegando cubo
  - [ ] `NAVIGATING_TO_BOX`: Indo para caixa correspondente
  - [ ] `DEPOSITING`: Depositando cubo
  - [ ] `AVOIDING`: Evitando obst√°culo (override)
- [ ] Transi√ß√µes entre estados
- [ ] Implementar em: `src/control/state_machine.py`

#### 3.3 Integra√ß√£o Controle
- [ ] Conectar fuzzy controller com state machine
- [ ] Input: dados de percep√ß√£o
- [ ] Output: comandos para base, arm, gripper
- [ ] Implementar em: `src/control/robot_controller.py`

**Deliverable:** Controlador fuzzy funcional com m√°quina de estados

**Refer√™ncias Fase 3:**
- Zadeh (1965): Fuzzy Sets theory
- Mamdani & Assilian (1975): Fuzzy controller
- Saffiotti (1997): Fuzzy navigation
- Antonelli et al. (2007): Path tracking

---

### Fase 4: Navega√ß√£o e Path Planning
**Prazo:** 5 dias
**Objetivo:** Implementar estrat√©gias de navega√ß√£o eficientes

#### 4.1 Mapeamento Local
- [ ] Criar occupancy grid simplificado
  - [ ] Baseado em leituras LIDAR recentes
  - [ ] Atualiza√ß√£o incremental
  - [ ] Resolu√ß√£o: 10cm x 10cm
- [ ] Marcar c√©lulas: livre, ocupado, desconhecido
- [ ] Implementar em: `src/navigation/local_map.py`

#### 4.2 Planejamento de Trajet√≥ria
- [ ] **Abordagem Simples (Recomendada):**
  - [ ] Navega√ß√£o reativa pura (fuzzy)
  - [ ] Sem path planning expl√≠cito
  - [ ] Evita√ß√£o local de obst√°culos
- [ ] **Abordagem Avan√ßada (Opcional):**
  - [ ] A* ou RRT para path planning
  - [ ] Planejar trajeto para cubo/caixa
  - [ ] Implementar em: `src/navigation/path_planner.py`

**Escolha:** Documentar em DECISIONS.md

#### 4.3 Localiza√ß√£o Relativa
- [ ] Odometria baseada em comandos de velocidade
- [ ] Estimativa de posi√ß√£o relativa (sem GPS!)
- [ ] Reset ao depositar cubo
- [ ] Implementar em: `src/navigation/odometry.py`

**Deliverable:** Sistema de navega√ß√£o funcional

**Refer√™ncias Fase 4:**
- Thrun et al. (2005): Probabilistic Robotics
- Siegwart et al. (2011): Mobile Robots

---

### Fase 5: Manipula√ß√£o e Grasping
**Prazo:** 4 dias
**Objetivo:** Sequ√™ncias confi√°veis de pegar e soltar cubos

#### 5.1 Sequ√™ncia de Grasping
- [ ] Definir posi√ß√µes do bra√ßo para pegar cubo:
  - [ ] Reset ‚Üí posi√ß√£o preparat√≥ria
  - [ ] Preparat√≥ria ‚Üí posi√ß√£o de pegada (FRONT_FLOOR)
  - [ ] Abrir garra
  - [ ] Descer bra√ßo at√© cubo
  - [ ] Fechar garra
  - [ ] Levantar bra√ßo
- [ ] Timing entre comandos (espera estabiliza√ß√£o)
- [ ] Verifica√ß√£o de sucesso (sensor de for√ßa ou timeout)
- [ ] Implementar em: `src/manipulation/grasping.py`

#### 5.2 Sequ√™ncia de Deposi√ß√£o
- [ ] Posicionar rob√¥ perto da caixa
- [ ] Mover bra√ßo para posi√ß√£o sobre caixa
- [ ] Abrir garra
- [ ] Retrair bra√ßo
- [ ] Reset para posi√ß√£o inicial
- [ ] Implementar em: `src/manipulation/depositing.py`

#### 5.3 Identifica√ß√£o das Caixas
- [ ] Mapear posi√ß√µes fixas das caixas (verde, azul, vermelha)
- [ ] Navega√ß√£o para caixa baseada na cor do cubo segurado
- [ ] Hardcode inicial de posi√ß√µes (simplifica√ß√£o)
- [ ] Opcional: Detec√ß√£o visual das caixas

**Deliverable:** Sequ√™ncias de manipula√ß√£o confi√°veis (>80% sucesso)

**Refer√™ncias Fase 5:**
- Craig (2005): Robot kinematics
- Bohg et al. (2014): Grasp synthesis

---

### Fase 6: Integra√ß√£o do Sistema Completo
**Prazo:** 5 dias
**Objetivo:** Loop principal funcionando end-to-end

#### 6.1 Arquitetura do Main Controller
- [ ] Implementar loop principal em: `src/main_controller.py`
```python
while cubos_coletados < 15:
    # 1. Percep√ß√£o
    obstacles, cubes = perception_system.update()

    # 2. Decis√£o (State Machine + Fuzzy)
    state, action = controller.decide(obstacles, cubes, robot_state)

    # 3. Atua√ß√£o
    if state == SEARCHING:
        base.move(vx, vy, omega)
    elif state == GRASPING:
        grasping.execute()
    elif state == DEPOSITING:
        depositing.execute()

    # 4. Update estado
    robot_state.update()

    step()
```

#### 6.2 Fluxo Completo
- [ ] Estado inicial: Busca
- [ ] Detec√ß√£o de cubo ‚Üí Aproxima√ß√£o
- [ ] Chegou perto ‚Üí Pegar
- [ ] Pegou ‚Üí Navegar para caixa
- [ ] Chegou na caixa ‚Üí Depositar
- [ ] Depositou ‚Üí Voltar para busca
- [ ] Repetir at√© 15 cubos

#### 6.3 Tratamento de Erros
- [ ] Timeout em estados (se travar)
- [ ] Retentar grasp se falhar
- [ ] Evitar ficar preso em cantos
- [ ] Log de eventos: `logs/execution.log`

#### 6.4 Testes de Integra√ß√£o
- [ ] Teste com 3 cubos primeiro
- [ ] Depois 5, 10, 15
- [ ] Diferentes configura√ß√µes de obst√°culos
- [ ] Medir taxa de sucesso

**Deliverable:** Sistema completo funcional

---

### Fase 7: Otimiza√ß√£o e Refinamento
**Prazo:** 5 dias
**Objetivo:** Melhorar performance e confiabilidade

#### 7.1 Ajuste de Par√¢metros
- [ ] Fuzzy:
  - [ ] Fun√ß√µes de pertin√™ncia
  - [ ] Pesos das regras
  - [ ] Thresholds de decis√£o
- [ ] Percep√ß√£o:
  - [ ] Thresholds de confian√ßa
  - [ ] Filtros de ru√≠do
- [ ] Navega√ß√£o:
  - [ ] Velocidades m√°ximas
  - [ ] Dist√¢ncias seguras
- [ ] Manipula√ß√£o:
  - [ ] Timings
  - [ ] Posi√ß√µes do bra√ßo

#### 7.2 M√©tricas de Performance
- [ ] Taxa de sucesso na coleta (%)
- [ ] Tempo m√©dio por cubo (s)
- [ ] N√∫mero de colis√µes
- [ ] Precis√£o na deposi√ß√£o por cor (%)
- [ ] Documentar em: `docs/performance_metrics.md`

#### 7.3 Debugging
- [ ] Adicionar logs detalhados
- [ ] Visualiza√ß√µes em tempo real:
  - [ ] Mapa LIDAR
  - [ ] Cubos detectados
  - [ ] Estado atual
- [ ] Modo de replay para an√°lise

**Deliverable:** Sistema otimizado com m√©tricas documentadas

---

### Fase 8: Documenta√ß√£o e Apresenta√ß√£o
**Prazo:** 7 dias
**Objetivo:** Material para v√≠deo de 15 minutos

#### 8.1 Documenta√ß√£o T√©cnica
- [ ] `README.md` com:
  - [ ] Descri√ß√£o do projeto
  - [ ] Como executar
  - [ ] Estrutura de c√≥digo
  - [ ] Depend√™ncias
- [ ] `docs/architecture.md`:
  - [ ] Diagramas de arquitetura
  - [ ] Fluxo de dados
  - [ ] Decis√µes de design
- [ ] `docs/results.md`:
  - [ ] M√©tricas finais
  - [ ] An√°lise de resultados

#### 8.2 Material Visual (SEM C√ìDIGO!)

**REGRA DE OURO:** Slides = IMAGENS E FIGURAS. Texto excessivo perde pontos!

- [ ] Adaptar template LaTeX: `slides-template/main.tex`
  - [ ] Atualizar t√≠tulo: "YouBot Aut√¥nomo - Sistema de Coleta com RNA + Fuzzy"
  - [ ] Autor: Luis Felipe Cordeiro Sena
  - [ ] Estrutura: 7 se√ß√µes (Intro, Teoria, Arquitetura, Percep√ß√£o, Controle, Demo, Resultados)
  - [ ] Integrar bibliografia (Top 10 de REFERENCIAS.md)
  - [ ] **M√°ximo 3-4 bullet points por slide, NUNCA par√°grafos**
- [ ] Roteiro de fala: `slides-template/falas.txt`
  - [ ] Ajustar para apresenta√ß√£o individual de 15 min
  - [ ] Sincronizar com estrutura de slides
  - [ ] Foco: Voc√™ explica verbalmente, slides s√≥ apoiam visualmente
- [ ] Diagramas:
  - [ ] Arquitetura do sistema
  - [ ] Pipeline de percep√ß√£o
  - [ ] Fun√ß√µes de pertin√™ncia fuzzy
  - [ ] Regras fuzzy (visual)
  - [ ] M√°quina de estados
  - [ ] Modelo cinem√°tico do YouBot
- [ ] Gr√°ficos:
  - [ ] Curvas de aprendizado (RNA)
  - [ ] M√©tricas de performance
  - [ ] Compara√ß√£o de abordagens
- [ ] V√≠deos/GIFs:
  - [ ] Rob√¥ coletando cubos (diferentes √¢ngulos)
  - [ ] Evita√ß√£o de obst√°culos
  - [ ] Sequ√™ncia de grasp
  - [ ] Visualiza√ß√£o LIDAR em tempo real
  - [ ] Detec√ß√£o de cubos com bounding boxes
- [ ] Ferramentas:
  - [ ] Draw.io para diagramas
  - [ ] Matplotlib/seaborn para gr√°ficos
  - [ ] OBS Studio para grava√ß√£o

#### 8.3 Roteiro do V√≠deo (15 min)
- [ ] **Intro (1 min):**
  - [ ] Apresenta√ß√£o do problema
  - [ ] Objetivos do projeto
- [ ] **Fundamenta√ß√£o Te√≥rica (3 min):**
  - [ ] Redes Neurais (LIDAR + C√¢mera)
  - [ ] L√≥gica Fuzzy (Controle)
  - [ ] Cita√ß√µes: Top 10 refer√™ncias
- [ ] **Arquitetura do Sistema (2 min):**
  - [ ] Diagrama completo
  - [ ] M√≥dulos e integra√ß√£o
- [ ] **Percep√ß√£o (2 min):**
  - [ ] Processamento LIDAR
  - [ ] Detec√ß√£o de cubos
  - [ ] Demonstra√ß√£o visual
- [ ] **Controle Fuzzy (2 min):**
  - [ ] Vari√°veis e regras
  - [ ] M√°quina de estados
  - [ ] Exemplos de decis√£o
- [ ] **Demonstra√ß√£o (4 min):**
  - [ ] V√≠deo do rob√¥ em a√ß√£o
  - [ ] Coleta completa de 15 cubos
  - [ ] Diferentes cen√°rios
- [ ] **Resultados (1 min):**
  - [ ] M√©tricas de performance
  - [ ] Taxa de sucesso
  - [ ] Gr√°ficos

#### 8.4 Grava√ß√£o e Edi√ß√£o
- [ ] Gravar √°udio (microfone de qualidade)
- [ ] Gravar tela com apresenta√ß√£o
- [ ] Gravar simula√ß√£o no Webots
- [ ] Editar no DaVinci Resolve / Premiere
- [ ] Adicionar legendas (opcional)
- [ ] M√∫sica de fundo discreta (opcional)
- [ ] Exportar em 1080p

#### 8.5 Submiss√£o
- [ ] Upload no Youtube (n√£o listado)
- [ ] C√≥digo em .zip
- [ ] Preencher formul√°rio de entrega
- [ ] Verificar prazo: **06/01/2026, 23:59**

**Deliverable:** V√≠deo de 15min + c√≥digo-fonte

**Refer√™ncias:** Todas as Top 10 de REFERENCIAS.md

---

## üèóÔ∏è Estrutura de C√≥digo Final

```
projeto-final-ia/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ perception/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lidar_processor.py       # RNA para LIDAR
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cube_detector.py         # CNN para cubos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ perception_system.py     # Integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ control/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fuzzy_controller.py      # L√≥gica Fuzzy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fuzzy_rules.txt          # Regras
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state_machine.py         # Estados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ robot_controller.py      # Integra√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ navigation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local_map.py             # Mapa local
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ odometry.py              # Odometria
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ path_planner.py          # Opcional
‚îÇ   ‚îú‚îÄ‚îÄ manipulation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grasping.py              # Sequ√™ncia grasp
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ depositing.py            # Sequ√™ncia deposi√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ main_controller.py           # Loop principal
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ lidar_model.pth              # Modelo LIDAR
‚îÇ   ‚îî‚îÄ‚îÄ cube_detector.pth            # Modelo CNN
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_basic_controls.py
‚îÇ   ‚îú‚îÄ‚îÄ test_perception.py
‚îÇ   ‚îú‚îÄ‚îÄ test_fuzzy.py
‚îÇ   ‚îî‚îÄ‚îÄ test_integration.py
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_sensor_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_lidar_training.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_cube_detection_training.ipynb
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ arena_map.md
‚îÇ   ‚îú‚îÄ‚îÄ fuzzy_membership.md
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md
‚îÇ   ‚îú‚îÄ‚îÄ performance_metrics.md
‚îÇ   ‚îî‚îÄ‚îÄ results.md
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ execution.log
‚îú‚îÄ‚îÄ media/
‚îÇ   ‚îú‚îÄ‚îÄ diagrams/
‚îÇ   ‚îú‚îÄ‚îÄ graphs/
‚îÇ   ‚îî‚îÄ‚îÄ videos/
‚îú‚îÄ‚îÄ IA_20252/                        # C√≥digo base (existente)
‚îú‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ REFERENCIAS.md
‚îú‚îÄ‚îÄ TODO.md                          # Este arquivo
‚îú‚îÄ‚îÄ DECISIONS.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ .gitignore
```

---

## üìä Cronograma Visual

```
Semanas 1-2:  [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] Fase 1-2: Setup + Percep√ß√£o (RNA)
Semanas 3:    [‚ñà‚ñà‚ñà‚ñà]     Fase 3: Controle Fuzzy
Semana 4:     [‚ñà‚ñà‚ñà]      Fase 4-5: Navega√ß√£o + Manipula√ß√£o
Semana 5:     [‚ñà‚ñà‚ñà‚ñà]     Fase 6: Integra√ß√£o
Semana 6:     [‚ñà‚ñà‚ñà]      Fase 7: Otimiza√ß√£o
Semanas 7-8:  [‚ñà‚ñà‚ñà‚ñà‚ñà]    Fase 8: Documenta√ß√£o + V√≠deo
                         [BUFFER: 1 semana antes da entrega]
```

**Total:** ~8 semanas + 1 buffer = 9 semanas at√© 06/01/2026

---

## ‚úÖ Crit√©rios de Sucesso

### M√≠nimo Vi√°vel (Aprova√ß√£o)
- [ ] Sistema coleta pelo menos 10/15 cubos
- [ ] Identifica√ß√£o de cores >80% precisa
- [ ] Evita√ß√£o de obst√°culos funcional
- [ ] RNA para LIDAR implementada e funcional
- [ ] L√≥gica Fuzzy implementada e funcional
- [ ] V√≠deo de 15min explicando tudo (SEM C√ìDIGO!)

### Excel√™ncia (Nota M√°xima)
- [ ] Sistema coleta 15/15 cubos consistentemente
- [ ] Identifica√ß√£o de cores >95% precisa
- [ ] Navega√ß√£o eficiente (tempo otimizado)
- [ ] Zero colis√µes com obst√°culos
- [ ] Apresenta√ß√£o visual impec√°vel
- [ ] Fundamenta√ß√£o te√≥rica s√≥lida
- [ ] C√≥digo bem documentado e organizado

---

## üîß Depend√™ncias T√©cnicas

### Python Packages
```txt
# requirements.txt
numpy>=1.24.0
scipy>=1.10.0
matplotlib>=3.7.0
scikit-learn>=1.3.0
scikit-fuzzy>=0.4.2
opencv-python>=4.8.0
torch>=2.0.0                # PyTorch para CNNs
torchvision>=0.15.0
pillow>=10.0.0
jupyter>=1.0.0
pytest>=7.4.0
```

### Instala√ß√£o
```bash
pip install -r requirements.txt
```

---

## üìù Notas Importantes

1. **Sem GPS:** Toda navega√ß√£o baseada em sensores (LIDAR + c√¢mera)
2. **Sem modificar supervisor.py:** Sob pena de perda de pontos
3. **Sem mostrar c√≥digo no v√≠deo:** Perda de 3-10 pontos
4. **Foco visual:** Figuras, gr√°ficos, v√≠deos > texto
5. **Prazo fatal:** 06/01/2026, 23:59
6. **Documentar tudo:** DECISIONS.md a cada escolha t√©cnica

---

## üéì Refer√™ncias por Fase

**Setup:** Michel (2004)
**Percep√ß√£o:** Goodfellow (2016), Qi (2017), Redmon (2016), Liu (2016)
**Controle:** Zadeh (1965), Mamdani (1975), Saffiotti (1997)
**Navega√ß√£o:** Thrun (2005), Siegwart (2011)
**Manipula√ß√£o:** Craig (2005), Bohg (2014)
**Integra√ß√£o:** Todas as Top 10

Ver REFERENCIAS.md para lista completa.

---

**√öltima atualiza√ß√£o:** 2025-11-18
**Pr√≥xima revis√£o:** Ap√≥s conclus√£o de cada fase
